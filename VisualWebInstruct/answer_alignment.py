"""
Answer Alignment Processor - A tool for validating and aligning answers using Google's Gemini API

INPUT:
- dataset1_path: Path to JSONL file containing first dataset (with questions and GPT answers)
- huggingface_repo: Repository ID for second dataset (with real answers)
- gemini_api_keys: List of Google Gemini API keys for load balancing
- image_dir: Directory containing images referenced in the datasets
- output_path: Path to save the processed dataset

OUTPUT:
- JSONL file containing processed entries with:
  - Original questions (modified with instruction to conclude with 'Answer: xxx')
  - Alignment status (aligned/not aligned)
  - Final answer (GPT's answer if aligned, real answer if not)
  - Explanation of alignment decision

The processor compares GPT-generated answers with real answers using Gemini's visual 
capabilities to determine if they are aligned. It processes entries concurrently using
multiple threads and cycles through API keys for load balancing.
"""

import json
import os
from typing import Dict, List, Optional
from google import generativeai as genai  # Corrected import
from tqdm import tqdm
from datasets import load_dataset
import base64
from pathlib import Path
import imghdr
from tenacity import retry, stop_after_attempt, wait_exponential
import logging
import concurrent.futures  # Import for threading
import itertools  # Import for cycling through API keys

# --- Setup logging ---
LOG_FILE_PATH = os.environ.get("LOG_FILE_PATH") or "answer_alignment.log"  # Default log filename

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    filename=LOG_FILE_PATH,  # Specify log file path
    filemode='w'  # 'w' mode overwrites previous log file, 'a' mode appends to it
)
# --- Configuration (using environment variables) ---
DATASET1_PATH = os.environ.get("DATASET1_PATH")  # Fallback path
HUGGINGFACE_REPO = os.environ.get("HUGGINGFACE_REPO")
GEMINI_API_KEYS_STR = os.environ.get("GEMINI_API_KEYS")
OUTPUT_PATH = os.environ.get("OUTPUT_PATH")
IMAGE_DIR = os.environ.get("IMAGE_DIR")
GEMINI_MODEL = os.environ.get("GEMINI_MODEL")  # Configurable model
MAX_CONCURRENT_THREADS = int(os.environ.get("MAX_CONCURRENT_THREADS") or 10) # Limit concurrent threads, default 10

def load_jsonl(file_path: str) -> List[Dict]:
    """Loads data from a JSONL file."""
    logging.info(f"Loading JSONL data from: {file_path}")
    data = []
    try:
        with open(file_path, 'r') as f:
            for line in f:
                data.append(json.loads(line))
        logging.info(f"Successfully loaded {len(data)} entries from {file_path}")
    except FileNotFoundError:
        logging.error(f"File not found: {file_path}")
        raise
    except json.JSONDecodeError as e:
        logging.error(f"JSONDecodeError in {file_path}: {e}")
        raise
    return data

def load_huggingface_dataset(repo_id: str) -> List[Dict]:
    """Loads a dataset from Hugging Face Datasets."""
    logging.info(f"Loading Hugging Face dataset from: {repo_id}")
    try:
        dataset = load_dataset(repo_id, name='raw', split='train') # Specify 'raw' config, limited for testing
        data = [item for item in dataset]
        logging.info(f"Successfully loaded {len(data)} entries from Hugging Face dataset: {repo_id}")
        return data
    except Exception as e:
        logging.error(f"Error loading Hugging Face dataset {repo_id}: {e}")
        raise

def create_index_map(dataset2: List[Dict]) -> Dict[int, Dict]:
    """Creates an index map from dataset2 using 'idx' as key."""
    logging.info("Creating index map for dataset2.")
    index_map = {entry['idx']: entry for entry in dataset2 if 'idx' in entry}
    logging.info(f"Index map created with {len(index_map)} entries.")
    return index_map

def load_image_as_base64(image_path: str) -> str:
    """Loads an image and encodes to base64."""
    try:
        with open(image_path, 'rb') as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except FileNotFoundError:
        logging.error(f"Image file not found: {image_path}")
        raise
    except Exception as e:
        logging.error(f"Error loading image {image_path}: {e}")
        raise

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10), reraise=True)  # Retry logic
def check_answer_alignment(question: str, gpt_answer: str, real_answer: str,
                            image_paths: List[str], image_dir: str,
                            gemini_api_key: str, gemini_model: str) -> Dict[str, str]:
    """
    Checks alignment between GPT and real answers using Gemini API.
    
    Args:
        question: The question text
        gpt_answer: Answer generated by GPT
        real_answer: Real reference answer
        image_paths: List of paths to images 
        image_dir: Base directory for images
        gemini_api_key: API key for Gemini
        gemini_model: Gemini model name to use
        
    Returns:
        Dictionary with alignment result and explanation
    """
    genai.configure(api_key=gemini_api_key) # Configure API key here
    model = genai.GenerativeModel(gemini_model)
    image_parts = []

    for img_path in image_paths:
        full_path = Path(image_dir) / img_path
        try:
            with open(str(full_path), 'rb') as f:
                mime_type = imghdr.what(str(full_path))
                if not mime_type:
                    logging.warning(f"MIME type detection failed for {img_path}. Assuming image/png")
                    mime_type = "png"
                image_parts.append({
                    "mime_type": f"image/{mime_type}",
                    "data": base64.b64encode(f.read()).decode('utf-8')
                })
        except FileNotFoundError:
            logging.warning(f"Image not found: {full_path}")
            continue
        except Exception as e:
            logging.warning(f"Error loading image {img_path}: {str(e)}")
            continue

    prompt = f"""Given the question and the provided image(s), compare these two answers and determine if they are aligned.

Question: {question}

GPT's Answer: {gpt_answer}

Real Answer: {real_answer}

Example of Aligned Answers: Question: What is 2 + 2? GPT Answer: 4 Real Answer: 4
Example of Misaligned Answers: Question: What is derivative of x^2? GPT Answer: 2x + 1 Real Answer: 2x

Are these answers aligned? Respond with just 'Yes' or 'No' on the first line. Provide a brief explanation on the second line."""

    try:
        response = model.generate_content(
            contents=[{"parts": [{"text": prompt}, *[{"inline_data": img} for img in image_parts]]}]
        )
        text_response = response.text.strip()
        lines = text_response.split('\n')
        aligned_str = lines[0].strip().lower()
        aligned = "yes" in aligned_str

        explanation = ""
        if len(lines) > 1:
            explanation = lines[1].strip()

        return {"aligned": str(aligned), "explanation": explanation}
    except Exception as e:
        logging.error(f"Gemini API call error: {str(e)}")
        return {"aligned": "False", "explanation": f"Gemini API Error: {e}"}

def process_single_entry(entry: Dict, dataset2_entry: Optional[Dict], gemini_api_key: str, image_dir: str, gemini_model: str) -> Dict:
    """
    Processes a single entry from dataset1.
    
    Args:
        entry: The entry to process from dataset1
        dataset2_entry: Corresponding entry from dataset2 (if exists)
        gemini_api_key: API key for Gemini
        image_dir: Base directory for images
        gemini_model: Gemini model name to use
        
    Returns:
        Processed entry with alignment information
    """
    old_idx = entry.get('old_idx')

    if old_idx is None:
        logging.warning(f"Entry missing 'old_index', skipping: {entry.get('question')[:50]}...")
        entry["alignment_explanation"] = "Skipped: Missing 'old_index'."
        entry["final_answer"] = entry['answer']
        entry["question"] = entry["question"] + '\n\nPlease conclude your answer as Answer: xxx at the end if possible.'
        entry["is_aligned"] = None
        return entry

    if dataset2_entry is None:
        logging.warning(f"No match in dataset2 for old_index: {old_idx}, skipping: {entry.get('question')[:50]}...")
        entry["alignment_explanation"] = f"Skipped: No match in dataset2 for old_index {old_idx}."
        entry["final_answer"] = entry['answer']
        entry["is_aligned"] = None  # Explicitly set is_aligned to False for skipped entries
        entry["question"] = entry["question"] + '\n\nPlease conclude your answer as Answer: xxx at the end if possible.'
        return entry

    if dataset2_entry['answer'].lower() == "not found":
        logging.warning(f"Real answer is 'not found' for old_idx: {old_idx}, using GPT's answer.")
        entry["alignment_explanation"] = "Skipped: Real answer 'not found', using GPT answer."
        entry["is_aligned"] = None # Explicitly set is_aligned to False
        entry["final_answer"] = entry['answer']
        entry["question"] = entry["question"] + '\n\nPlease conclude your answer as Answer: xxx at the end if possible.'
        return entry


    try:
        alignment_result = check_answer_alignment(
            entry['question'], entry['answer'], dataset2_entry['answer'],
            entry.get('image', []), image_dir, gemini_api_key, gemini_model
        )
        is_aligned = alignment_result["aligned"].lower() == "true"
        explanation = alignment_result["explanation"]
        entry["is_aligned"] = is_aligned
        entry["alignment_explanation"] = explanation
        if is_aligned:
            entry["final_answer"] = entry['answer']
            entry["question"] = entry["question"] + '\n\nPlease conclude your answer as Answer: xxx at the end if possible.'
        else:
            entry["final_answer"] = dataset2_entry['answer']

    except Exception as e:
        logging.error(f"Error processing entry {old_idx}: {str(e)}")
        entry["is_aligned"] = None
        entry["alignment_explanation"] = f"Processing Error: {str(e)}"
        entry["final_answer"] = entry['answer']
        entry["question"] = entry["question"] + '\n\nPlease conclude your answer as Answer: xxx at the end if possible.'
    return entry


def process_datasets(dataset1_path: str, dataset2: List[Dict],
                     gemini_api_keys: List[str], output_path: str, image_dir: str, gemini_model: str): # Expecting a list of API keys
    """
    Processes dataset1 using multiple threads and API keys.
    
    Args:
        dataset1_path: Path to dataset1 JSONL file
        dataset2: List of entries from dataset2
        gemini_api_keys: List of API keys for Gemini
        output_path: Path to save processed output
        image_dir: Base directory for images
        gemini_model: Gemini model name to use
    """
    processed_data = []
    index_map = create_index_map(dataset2)
    dataset1 = load_jsonl(dataset1_path)

    logging.info(f"Starting dataset processing with {MAX_CONCURRENT_THREADS} threads and {len(gemini_api_keys)} API keys.")

    api_key_cycle = itertools.cycle(gemini_api_keys) # Create a cycling iterator for API keys

    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_CONCURRENT_THREADS) as executor:
        futures = []
        for entry in dataset1:
            old_idx = entry.get('old_idx')
            dataset2_entry = index_map.get(old_idx)
            api_key = next(api_key_cycle) # Get the next API key in the cycle
            future = executor.submit(process_single_entry, entry, dataset2_entry, api_key, image_dir, gemini_model)
            futures.append(future)

        for future in tqdm(concurrent.futures.as_completed(futures), total=len(dataset1), desc="Processing entries"):
            processed_entry = future.result() # Get the processed entry from the future
            processed_data.append(processed_entry)


    logging.info(f"Saving processed data to: {output_path}")
    with open(output_path, 'w') as outfile:
        for entry in processed_data:
            if "answer" in entry:
                del entry["answer"]
            json.dump(entry, outfile, ensure_ascii=False)
            outfile.write('\n')
    logging.info(f"Processing complete. Output saved to {output_path}")


def main():
    """Main function to load datasets and process them using threads and multiple API keys."""
    logging.info("Starting main function.")

    # Load dataset2
    if HUGGINGFACE_REPO:
        dataset2 = load_huggingface_dataset(HUGGINGFACE_REPO)
    else:
        logging.warning("HUGGINGFACE_REPO not set, ensure dataset2 is loaded.")
        dataset2 = []

    # Load API keys from environment variable
    gemini_api_keys = [key.strip() for key in GEMINI_API_KEYS_STR.split(',')]
    if not gemini_api_keys or not gemini_api_keys[0]: # Check if list is empty or first key is empty string
        logging.error("No Gemini API keys provided. Please set GEMINI_API_KEYS environment variable.")
        return

    logging.info(f"Loaded {len(gemini_api_keys)} API keys.")

    # Process datasets with threading and multiple API keys
    logging.info("Starting dataset processing with threads and multiple API keys...")
    process_datasets(DATASET1_PATH, dataset2, gemini_api_keys, OUTPUT_PATH, IMAGE_DIR, GEMINI_MODEL) # Pass the list of API keys
    logging.info(f"Processing complete. Output saved to {OUTPUT_PATH}")


if __name__ == "__main__":
    main()